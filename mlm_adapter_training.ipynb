{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8c4137-5f92-414e-bfc4-f066ea09e159",
   "metadata": {},
   "source": [
    "## Masked Language Modeling\n",
    "Using MLM, we train adapters for each of the GLUE tasks. This adapts the pre-trained language model to the language corpus specific to the GLUE task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32108f05-65f9-4708-b279-ad2a33100220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -Uqq adapter-transformers datasets\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.mlm import masked_language_modeling\n",
    "from utils.mlm_utils import DomainModelArguments, DomainDataTrainingArguments\n",
    "from transformers import TrainingArguments, MultiLingAdapterArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d797d3-e32f-4cd7-835f-b88c06ee7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "glue_tasks = [\n",
    "    #\"cola\",\n",
    "    #\"mnli\",\n",
    "    \"mrpc\",\n",
    "    #\"qnli\",\n",
    "    #\"qqp\",\n",
    "    #\"rte\",\n",
    "    #\"sst2\",\n",
    "    #\"stsb\",\n",
    "    #\"wnli\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec35e6-87d8-48e1-83b4-8e0bb0cfc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DomainModelArguments(\n",
    "    model_name_or_path=\"roberta-base\",\n",
    ")\n",
    "\n",
    "adapter = MultiLingAdapterArguments(\n",
    "    train_adapter=True,\n",
    "    adapter_config=\"pfeiffer+inv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb9949-5ca7-40b5-bbff-8ca186dbe7d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "results = {}\n",
    "for dataset in glue_tasks[:1]:\n",
    "    data = DomainDataTrainingArguments(\n",
    "        dataset_name=\"glue\",\n",
    "        dataset_config_name=dataset,\n",
    "    )\n",
    "    \n",
    "    training = TrainingArguments(\n",
    "        learning_rate=1e-4,\n",
    "        overwrite_output_dir=True,\n",
    "        output_dir=f\"./adapter/mlm/{dataset}\",\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        num_train_epochs=10,\n",
    "    )\n",
    "\n",
    "    train_stats, eval_stats = masked_language_modeling(\n",
    "        model_args=model, data_args=data, training_args=training, adapter_args=adapter\n",
    "    )\n",
    "    \n",
    "    results[dataset] = {\"training\" : train_stats, \"eval\" : eval_stats}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc1017-3f73-49c3-b188-0e7bd4971f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
