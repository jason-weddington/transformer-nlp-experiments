{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29d6932",
   "metadata": {
    "id": "30c9495f-baf7-4460-ab80-8860fb681e8e"
   },
   "source": [
    "## Training Task Adapters\n",
    "Using randomized search, we identify optimal hyperparameters to train task specfic adapters on GLUE tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a36b615",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14598,
     "status": "ok",
     "timestamp": 1627331551612,
     "user": {
      "displayName": "Snow Cones",
      "photoUrl": "",
      "userId": "05757556542173404456"
     },
     "user_tz": 240
    },
    "id": "KdDh2RdkTRxi",
    "outputId": "0e461b18-4985-4f09-cb45-dfe2e2a47322"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bebb83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1627331553058,
     "user": {
      "displayName": "Snow Cones",
      "photoUrl": "",
      "userId": "05757556542173404456"
     },
     "user_tz": 240
    },
    "id": "BQjODWExTcpq",
    "outputId": "e92c101a-3cb2-4243-c0dc-3c398b6333ba"
   },
   "outputs": [],
   "source": [
    "# cd drive/MyDrive/cs7643-deep-learning-summer-2021/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e8cb96-3d93-4d2f-a448-d908768a6af1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16466,
     "status": "ok",
     "timestamp": 1627331572588,
     "user": {
      "displayName": "Snow Cones",
      "photoUrl": "",
      "userId": "05757556542173404456"
     },
     "user_tz": 240
    },
    "id": "9889c970-bdb0-464f-953d-78c2224b76fe",
    "outputId": "c6ed4418-74d9-425b-cd05-e53d99f74100"
   },
   "outputs": [],
   "source": [
    "# !pip install -Uqq adapter-transformers datasets\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from time import time\n",
    "from typing import Dict, List\n",
    "from task_utils import TaskModelArguments, TaskDataTrainingArguments\n",
    "from task import train_task_adapter\n",
    "from transformers import (\n",
    "    MultiLingAdapterArguments,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9d3eb",
   "metadata": {
    "id": "33aa90b1-82cb-41e8-b38d-e6fceb42f486"
   },
   "source": [
    "### Utility Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e718ccd-ba80-4b24-8476-7b5652d1b687",
   "metadata": {
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1627331575013,
     "user": {
      "displayName": "Snow Cones",
      "photoUrl": "",
      "userId": "05757556542173404456"
     },
     "user_tz": 240
    },
    "id": "oEFf_pUPYdWU"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "def getParams(dictionary, limit):\n",
    "    paramsList = [dict(zip(dictionary, v)) for v in itertools.product(*dictionary.values())]\n",
    "    random.shuffle(paramsList)\n",
    "\n",
    "    if limit is not False:\n",
    "        paramsList = paramsList[0:min(limit, len(paramsList))]\n",
    "\n",
    "    return paramsList\n",
    "\n",
    "def initParse(dictionary: Dict, output_prefix = \"\"):\n",
    "    model = TaskModelArguments(\n",
    "        model_name_or_path=dictionary.get('model_name_or_path')\n",
    "    )\n",
    "\n",
    "    data = TaskDataTrainingArguments(\n",
    "        task_name=dictionary.get('task_name'),\n",
    "        max_seq_length=dictionary.get('max_seq_length'),\n",
    "        pad_to_max_length=dictionary.get('pad_to_max_length')\n",
    "    )\n",
    "\n",
    "    training = TrainingArguments(\n",
    "        adam_beta1=dictionary.get('adam_beta1'),\n",
    "        adam_beta2=dictionary.get('adam_beta2'),\n",
    "        adam_epsilon=dictionary.get('adam_epsilon'),\n",
    "        learning_rate=dictionary.get('learning_rate'),\n",
    "        fp16=dictionary.get('fp16'),\n",
    "        warmup_ratio=dictionary.get('warmup_ratio'),\n",
    "        warmup_steps=dictionary.get('warmup_steps'),\n",
    "        weight_decay=dictionary.get('weight_decay'),\n",
    "        do_train=dictionary.get('do_train'),\n",
    "        do_eval=dictionary.get('do_train'),\n",
    "        per_device_train_batch_size=dictionary.get('per_device_train_batch_size'),\n",
    "        num_train_epochs=dictionary.get('num_train_epochs'), # CHANGE ME\n",
    "        overwrite_output_dir=dictionary.get('overwrite_output_dir'),\n",
    "        output_dir=f\"./adapter/task/{output_prefix}{dictionary.get('task_name')}\",\n",
    "    )\n",
    "\n",
    "    adapter = MultiLingAdapterArguments(\n",
    "        train_adapter=True,\n",
    "        adapter_config=\"pfeiffer\",\n",
    "    )\n",
    "\n",
    "    return model, data, training, adapter\n",
    "\n",
    "def train(params: Dict, output_prefix = \"\") -> List:\n",
    "    model, data, training, adapter = initParse(params, output_prefix)\n",
    "    \n",
    "    train_stats, eval_stats = train_task_adapter(\n",
    "        model_args=model, \n",
    "        adapter_args=adapter, \n",
    "        training_args=training, \n",
    "        data_args=data\n",
    "    )\n",
    "    \n",
    "    row = []\n",
    "    row.extend(list(params.values()))\n",
    "    row.extend(list(train_stats.values()))\n",
    "    row.extend(list(eval_stats.values()))\n",
    "    \n",
    "    header = []\n",
    "    header.extend(list(params.keys()))\n",
    "    header.extend(list(train_stats.keys()))\n",
    "    header.extend(list(eval_stats.keys()))\n",
    "\n",
    "    output_df = pd.DataFrame([row], columns=header)\n",
    "    \n",
    "    del model\n",
    "    del data\n",
    "    del training\n",
    "    del adapter\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22451996-72ae-4fe8-8a65-e6ecc89e25e4",
   "metadata": {},
   "source": [
    "## Random Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb130ac9",
   "metadata": {
    "id": "FZR2TOk1hZyT",
    "tags": []
   },
   "source": [
    "**Define Dictionary of Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3030f-43e4-4063-a922-a4376ed66743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glue_tasks = [\n",
    "    #\"cola\",\n",
    "    #\"mnli\",\n",
    "    #\"mrpc\",\n",
    "    #\"qnli\",\n",
    "    #\"qqp\",\n",
    "    #\"rte\",\n",
    "    \"sst2\",\n",
    "    #\"stsb\",\n",
    "    #\"wnli\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a7b2f",
   "metadata": {
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1627331583420,
     "user": {
      "displayName": "Snow Cones",
      "photoUrl": "",
      "userId": "05757556542173404456"
     },
     "user_tz": 240
    },
    "id": "F1FN14CdVqFP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = 'cola'\n",
    "paramDictionary = {\n",
    "    'task_name':[task],\n",
    "    'model_name_or_path':['roberta-base'],\n",
    "    'max_seq_length':[64, 128, 256],\n",
    "    'pad_to_max_length':[True],\n",
    "    'per_device_train_batch_size':[16, 32, 64],\n",
    "    'adam_beta1':[.9],\n",
    "    'adam_beta2':[.999],\n",
    "    'adam_epsilon':[1e-8,1e-7,1e-6],\n",
    "    'fp16':[True],\n",
    "    'learning_rate':[1e-5,5e-5,1e-4,5e-4,1e-3],\n",
    "    'warmup_ratio':[0.0],\n",
    "    'warmup_steps':[0],\n",
    "    'weight_decay':[0.0],\n",
    "    'do_train':[True],\n",
    "    'do_eval':[True],\n",
    "    'num_train_epochs':[10],\n",
    "    'overwrite_output_dir':[True],\n",
    "    'adapter_config':['pfeiffer']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221eee26",
   "metadata": {
    "id": "CHmh6eeThiTm",
    "tags": []
   },
   "source": [
    "**Begin Looping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2372beb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "beab7a6853464a2fb9da17c3a0c53f80",
      "06e9193555754f3c820fb47c9322925d",
      "d9c12bc752e745149f3d3e0edf93fe10",
      "8d12e917320e4de7ad3bd165a4f991bf",
      "7f5b43aafb754ccd82c11b0f7fa6b210",
      "2d64c717a1354cefab8b3c9e6334577e",
      "99a900f85059444581e93cb6ec686c4d",
      "3c3c6c0c806e417db227ad8afe80335e",
      "ccac7134e00a4f6581d80ca2943a0fcf",
      "3ee4cb3cecf0451f925dc34ed709d2a0",
      "c8bbed77890e4deb9d9263c95310a42a",
      "0a67106bdf5740baa70ccdced2ddc14e",
      "7ec6b5f9910f4a6da32473732eb96508",
      "5a12798be0d44c5fbbcfff260f366b68",
      "0e0ea8ae0cca4ab0914bb608a721aa18",
      "c00d73694fdb483d9d1f2a0e4334e890",
      "7a4a19a374ca47e5ace3a71fef6f4179",
      "bdea7284db604e26af00969e632fe1d3",
      "bcd6ce6c84574455ba3dd425e2267241",
      "310079aaacc443a98064000f342261a8",
      "a8915cd5793a408092c6d0e7357c6ba1",
      "83aa40a78b5e4f5593190fb8751f1f21"
     ]
    },
    "executionInfo": {
     "elapsed": 885367,
     "status": "ok",
     "timestamp": 1627335786995,
     "user": {
      "displayName": "Snow Cones",
      "photoUrl": "",
      "userId": "05757556542173404456"
     },
     "user_tz": 240
    },
    "id": "uEcrWpiJbyed",
    "outputId": "f517ea12-a23e-4b6e-bd83-62614f8acf1c",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "limit = 15 #Numerical or False for no limit\n",
    "\n",
    "for data_set in glue_tasks:\n",
    "    paramDictionary[\"task_name\"] = [data_set]\n",
    "    paramsList = getParams(paramDictionary, limit)\n",
    "\n",
    "    results = None\n",
    "    for p in paramsList:\n",
    "        trial_data = train(p)\n",
    "        \n",
    "        if results is not None:\n",
    "            results = results.append(trial_data)\n",
    "        else:\n",
    "            results = trial_data #first pass through the loop\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "    results.to_csv(f\"./adapter/task/{data_set}_hp_search.{time():.0f}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88958964-0df8-4786-b69b-61d702e2d7c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4d8a3-2f84-4dde-ab1c-432319390c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.to_csv(f\"./adapter/task/{data_set}_hp_search.{time():.0f}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a46d41-3028-4371-b7ba-e2af84c03004",
   "metadata": {},
   "source": [
    "## Final Training\n",
    "Training each adapter again with the optimal settings discovered through the random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "609c37e0-d2c3-451d-b9eb-2d1a51285e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def final_training(\n",
    "    task, \n",
    "    learning_rate, \n",
    "    max_seq_length, \n",
    "    per_device_train_batch_size, \n",
    "    adam_epsilon,\n",
    "    num_train_epochs\n",
    "    ):\n",
    "    \n",
    "    home = str(Path.home())\n",
    "    final_params = {\n",
    "        'task_name':[task],\n",
    "        'model_name_or_path':[f'{home}/git/roberta-base'],\n",
    "        'max_seq_length':[max_seq_length],\n",
    "        'pad_to_max_length':[True],\n",
    "        'per_device_train_batch_size':[per_device_train_batch_size],\n",
    "        'adam_beta1':[.9],\n",
    "        'adam_beta2':[.999],\n",
    "        'adam_epsilon':[adam_epsilon],\n",
    "        'fp16':[True],\n",
    "        'learning_rate':[learning_rate],\n",
    "        'warmup_ratio':[0.0],\n",
    "        'warmup_steps':[0],\n",
    "        'weight_decay':[0.0],\n",
    "        'do_train':[True],\n",
    "        'do_eval':[True],\n",
    "        'num_train_epochs':[num_train_epochs],\n",
    "        'overwrite_output_dir':[True],\n",
    "        'adapter_config':[\"pfeiffer\"]\n",
    "    }\n",
    "    \n",
    "    prefix = \"final_\"\n",
    "    p = getParams(final_params, 1)\n",
    "    result = train(params=p[0], output_prefix=prefix)\n",
    "    result.to_csv(f\"./adapter/task/{prefix}{task}_hp_search.{time():.0f}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0af122c-52d9-47c4-9c12-9ad2846d489a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/30/2021 19:51:17 - WARNING - task -   Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: True\n",
      "07/30/2021 19:51:17 - INFO - task -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=4,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-07,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=500,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./adapter/task/final_sst2/runs/Jul30_19-51-15_ip-172-16-1-120,\n",
      "logging_first_step=False,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=20,\n",
      "output_dir=./adapter/task/final_sst2,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=final_sst2,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./adapter/task/final_sst2,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "07/30/2021 19:51:17 - WARNING - datasets.builder -   Reusing dataset glue (/home/ubuntu/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "loading configuration file /home/ubuntu/git/roberta-base/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"sst2\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file /home/ubuntu/git/roberta-base/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Didn't find file /home/ubuntu/git/roberta-base/added_tokens.json. We won't load it.\n",
      "Didn't find file /home/ubuntu/git/roberta-base/special_tokens_map.json. We won't load it.\n",
      "Didn't find file /home/ubuntu/git/roberta-base/tokenizer_config.json. We won't load it.\n",
      "loading file /home/ubuntu/git/roberta-base/vocab.json\n",
      "loading file /home/ubuntu/git/roberta-base/merges.txt\n",
      "loading file /home/ubuntu/git/roberta-base/tokenizer.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading weights file /home/ubuntu/git/roberta-base/pytorch_model.bin\n",
      "Some weights of the model checkpoint at /home/ubuntu/git/roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at /home/ubuntu/git/roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding head 'sst2' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'negative': 0, 'positive': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Adding adapter 'sst2'.\n",
      "07/30/2021 19:51:18 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1aeae2e9685f7340.arrow\n",
      "07/30/2021 19:51:18 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a1a51d2078d4249c.arrow\n",
      "07/30/2021 19:51:18 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ba6b76ea4198fc07.arrow\n",
      "07/30/2021 19:51:18 - INFO - task -   Sample 14592 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 14592, 'input_ids': [0, 102, 372, 1569, 1437, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 1, 'sentence': 'a great movie '}.\n",
      "07/30/2021 19:51:18 - INFO - task -   Sample 3278 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 3278, 'input_ids': [0, 1342, 2399, 8173, 2156, 114, 5568, 28631, 2156, 814, 1437, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 1, 'sentence': 'entertaining , if somewhat standardized , action '}.\n",
      "07/30/2021 19:51:18 - INFO - task -   Sample 36048 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 36048, 'input_ids': [0, 12963, 77, 89, 32, 29620, 29, 2156, 5, 8597, 2045, 12757, 2156, 1437, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 1, 'sentence': 'even when there are lulls , the emotions seem authentic , '}.\n",
      "Using amp fp16 backend\n",
      "/home/ubuntu/.local/share/virtualenvs/cs7643-deep-learning-summer-2021-h1yaMy-h/lib/python3.8/site-packages/transformers/trainer.py:1052: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
      "  warnings.warn(\n",
      "Loading model from /home/ubuntu/git/roberta-base).\n",
      "Loading module configuration from /home/ubuntu/git/roberta-base/.git/adapter_config.json\n",
      "Overwriting existing adapter 'sst2'.\n",
      "Loading module weights from /home/ubuntu/git/roberta-base/.git/pytorch_adapter.bin\n",
      "Loading module configuration from /home/ubuntu/git/roberta-base/.git/head_config.json\n",
      "Overwriting existing head 'sst2'\n",
      "Adding head 'sst2' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'negative': 0, 'positive': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from /home/ubuntu/git/roberta-base/.git/pytorch_model_head.bin\n",
      "The following columns in the training set  don't have a corresponding argument in `RobertaModelWithHeads.forward` and have been ignored: idx, sentence.\n",
      "***** Running training *****\n",
      "  Num examples = 67349\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10540\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3225/146976777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' cp ./adapter/task/sst2/sst2/* ~/git/roberta-base/.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sst2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m final_training(task=task,\n\u001b[0m\u001b[1;32m      5\u001b[0m                \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3225/3056210545.py\u001b[0m in \u001b[0;36mfinal_training\u001b[0;34m(task, learning_rate, max_seq_length, per_device_train_batch_size, adam_epsilon, num_train_epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"final_\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./adapter/task/{prefix}{task}_hp_search.{time():.0f}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3225/314586028.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, output_prefix)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     train_stats, eval_stats = train_task_adapter(\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mmodel_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0madapter_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/cs7643-deep-learning-summer-2021/task.py\u001b[0m in \u001b[0;36mtrain_task_adapter\u001b[0;34m(model_args, adapter_args, data_args, training_args)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0mtraining_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         training_stats = trainer.train(\n\u001b[0m\u001b[1;32m    374\u001b[0m             \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cs7643-deep-learning-summer-2021-h1yaMy-h/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cs7643-deep-learning-summer-2021-h1yaMy-h/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1834\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1836\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1837\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cs7643-deep-learning-summer-2021-h1yaMy-h/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1868\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1870\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1871\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cs7643-deep-learning-summer-2021-h1yaMy-h/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cs7643-deep-learning-summer-2021-h1yaMy-h/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_device_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                     raise RuntimeError(\"module must have its parameters and buffers \"\n\u001b[0m\u001b[1;32m    155\u001b[0m                                        \u001b[0;34m\"on device {} (device_ids[0]) but found one of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                                        \"them on device: {}\".format(self.src_device_obj, t.device))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu"
     ]
    }
   ],
   "source": [
    "#sst2\n",
    "task = \"sst2\"\n",
    "! cp ./adapter/task/sst2/sst2/* ~/git/roberta-base/.git\n",
    "final_training(task=task,\n",
    "               learning_rate=5e-4,\n",
    "               max_seq_length=64,\n",
    "               per_device_train_batch_size=32,\n",
    "               adam_epsilon=1e-7,\n",
    "               num_train_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d5e926-244a-4eb7-90f9-eb3ddc706cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "task_adapter_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06e9193555754f3c820fb47c9322925d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a67106bdf5740baa70ccdced2ddc14e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a12798be0d44c5fbbcfff260f366b68",
       "IPY_MODEL_0e0ea8ae0cca4ab0914bb608a721aa18",
       "IPY_MODEL_c00d73694fdb483d9d1f2a0e4334e890"
      ],
      "layout": "IPY_MODEL_7ec6b5f9910f4a6da32473732eb96508"
     }
    },
    "0e0ea8ae0cca4ab0914bb608a721aa18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_310079aaacc443a98064000f342261a8",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bcd6ce6c84574455ba3dd425e2267241",
      "value": 2
     }
    },
    "2d64c717a1354cefab8b3c9e6334577e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "310079aaacc443a98064000f342261a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c3c6c0c806e417db227ad8afe80335e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ee4cb3cecf0451f925dc34ed709d2a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a12798be0d44c5fbbcfff260f366b68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdea7284db604e26af00969e632fe1d3",
      "placeholder": "​",
      "style": "IPY_MODEL_7a4a19a374ca47e5ace3a71fef6f4179",
      "value": "100%"
     }
    },
    "7a4a19a374ca47e5ace3a71fef6f4179": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ec6b5f9910f4a6da32473732eb96508": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f5b43aafb754ccd82c11b0f7fa6b210": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8bbed77890e4deb9d9263c95310a42a",
      "placeholder": "​",
      "style": "IPY_MODEL_3ee4cb3cecf0451f925dc34ed709d2a0",
      "value": " 2/2 [00:00&lt;00:00,  9.47ba/s]"
     }
    },
    "83aa40a78b5e4f5593190fb8751f1f21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d12e917320e4de7ad3bd165a4f991bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccac7134e00a4f6581d80ca2943a0fcf",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c3c6c0c806e417db227ad8afe80335e",
      "value": 2
     }
    },
    "99a900f85059444581e93cb6ec686c4d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8915cd5793a408092c6d0e7357c6ba1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcd6ce6c84574455ba3dd425e2267241": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bdea7284db604e26af00969e632fe1d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "beab7a6853464a2fb9da17c3a0c53f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9c12bc752e745149f3d3e0edf93fe10",
       "IPY_MODEL_8d12e917320e4de7ad3bd165a4f991bf",
       "IPY_MODEL_7f5b43aafb754ccd82c11b0f7fa6b210"
      ],
      "layout": "IPY_MODEL_06e9193555754f3c820fb47c9322925d"
     }
    },
    "c00d73694fdb483d9d1f2a0e4334e890": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83aa40a78b5e4f5593190fb8751f1f21",
      "placeholder": "​",
      "style": "IPY_MODEL_a8915cd5793a408092c6d0e7357c6ba1",
      "value": " 2/2 [00:00&lt;00:00,  6.16ba/s]"
     }
    },
    "c8bbed77890e4deb9d9263c95310a42a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccac7134e00a4f6581d80ca2943a0fcf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9c12bc752e745149f3d3e0edf93fe10": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99a900f85059444581e93cb6ec686c4d",
      "placeholder": "​",
      "style": "IPY_MODEL_2d64c717a1354cefab8b3c9e6334577e",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
